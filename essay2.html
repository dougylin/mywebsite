<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hardware Programs</title>
    <link href="https://fonts.googleapis.com/css?family=Libre+Franklin:300,400,600" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>

    <div class="container">
        <div class="text animate">
            <h3>
                <span id=></span>The Automation Question <!-- bold header -->
            </h3>

            <p>
                <strong>The question</strong>  
	    	    Software engineering (SWE), accounting, and law professionals are constantly debating the AI question.
                CS students in 2024 are experiencing 2001 vibes of tech recession unemployability.
                I think there is a fundamental misundertanding of what's being automated. 
                Lower level work in these field will go. Below average professionals will be brought up to the average
                of the best AI model. Middle/average professionals will either make the jump to elite practioners/specialties 
                or be relegated to the pool of averageness and mediocracty set by their reliance on AI.
            </p>

            <p>
                One thing these fields have in common is that AI cannot replace the core job function of "auditing" an AI's output.
                The techno-philosophical question of can we hold black-box machines liable is likely to be answered by
                their creators. However, superceeding business interests will answer it first, seeking to 
                limit legal liability, completely abdicate responsibility, 
                or create "safety" mechanisms, which have historically been controversial but necessary. 
                Reviewing the outputs will be the core job function of the average worker, which will be the next 
                evolution in the Western service sector hegemony. The offshoring trend can be viewed as a stack. 
                Countries that get outsourced to have their worked checked upstream. All AI does is insert itself into the stack. 
            </p>

            <p>
                <strong>What about AGI?</strong>  
                I agree, LLM's may be able to replace 80% existing white collar jobs. Just not anytime these next five years. 
                Side note: robotics and multimodal physical models, the type you 
                want in robotics, will be the last frontier. Hence why everyone talks about nurses never going away etc.
                I don't think LLMs will get us to AGI. The state of AI Agents in 2024 is underwhelming. Data is too unorganized in industry and 
                unless a task is rote, it's not AI'able right now.
                <a href="https://github.com/AI-App/OpenDevin.OpenDevin" target="_blank">OpenDevin</a> is my rough benchmark for where 
                we're at.  
            </p>
            
            <p>
                This reminds me of the AI driving question. If AI drivers are statiscally safer than human ones, everyone should be required to
                never drive again. Will there be a statisical threshold where AI will better in X areas to where the cost-benefit will tip? 
            </p>

            <p></p>


	    <p>

	    </p>

        </div>
    </div>
</body>
</html>
